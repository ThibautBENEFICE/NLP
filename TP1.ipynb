{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "!pip install nltk"
      ],
      "metadata": {
        "id": "mw_BB0wSUJBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pShVyi91RTlk"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset_train = load_dataset('imdb', split='train')\n",
        "dataset_test = load_dataset('imdb', split='test')\n",
        "dataset_unsupervised = load_dataset('imdb', split='unsupervised')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set(dataset_train['label'])"
      ],
      "metadata": {
        "id": "Nvz2k-s8Ybnv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_test['label'][12490:12010]"
      ],
      "metadata": {
        "id": "BYbIywQxkCB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train['label'].count(0), dataset_train['label'].count(1), dataset_test['label'].count(0), dataset_test['label'].count(1), "
      ],
      "metadata": {
        "id": "eeSc7CspUwMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Naive Bayes classifier"
      ],
      "metadata": {
        "id": "ShA0mmaUZZdi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(2 points) Take a look at the data and create an adapted preprocessing function which at least:\n",
        "- Lower case the text."
      ],
      "metadata": {
        "id": "fLphY4skPm32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def to_lower(in_list: list) -> str:\n",
        "  return list(map(str.lower, in_list))"
      ],
      "metadata": {
        "id": "2R5DlVcxY0fV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lower_train = to_lower(dataset_train['text'])\n",
        "len(dataset_train['text'])"
      ],
      "metadata": {
        "id": "j6NhmQN6O9xt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Remove punctuation (you can use from string import punctuation to ease your work)."
      ],
      "metadata": {
        "id": "TGoUiGBcP0tF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from string import punctuation\n",
        "def remove_punct(in_list: list) -> str:\n",
        "  return list(map(lambda input : input.translate(str.maketrans('', '', punctuation)), in_list))"
      ],
      "metadata": {
        "id": "DI9sChrwZYew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(4 points) Implement and train a naive Bayes classifier on the training data. Either:\n",
        "- We used a scikit-learn Pipeline with a CountVectorizer and MultinomialNB classifier."
      ],
      "metadata": {
        "id": "Am5BMrGDP82d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = remove_punct(lower_train)\n",
        "X_train[0]"
      ],
      "metadata": {
        "id": "_4MGHg6kO8Bu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB"
      ],
      "metadata": {
        "id": "-oRWsRTHesGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer_train = CountVectorizer()\n",
        "X = vectorizer_train.fit_transform(X_train)\n",
        "y_train = dataset_train['label']"
      ],
      "metadata": {
        "id": "UXyJJp91gDyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X[:5].toarray()"
      ],
      "metadata": {
        "id": "DknwY0cFhM0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = MultinomialNB()\n",
        "clf.fit(X, dataset_train['label'])\n",
        "print(clf.predict(X[100]))"
      ],
      "metadata": {
        "id": "s0piMb90j2tS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pipeline tests\n",
        "lower_test = to_lower(dataset_test['text'])\n",
        "no_punct_test =  remove_punct(lower_test)\n",
        "X_test = vectorizer_train.transform(no_punct_test)"
      ],
      "metadata": {
        "id": "d0m8ZxqWkcJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(clf.predict(X_test[20000:20050]))"
      ],
      "metadata": {
        "id": "5iKwvH6ikywk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = make_pipeline(CountVectorizer(), MultinomialNB())\n",
        "pipeline, pipeline.steps"
      ],
      "metadata": {
        "id": "oXPN8uk4mTHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline.fit(X_train, y_train)\n",
        "pipeline.score(X_train, y_train)"
      ],
      "metadata": {
        "id": "htwVvdoY8WGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = no_punct_test\n",
        "y_test = dataset_train['label']"
      ],
      "metadata": {
        "id": "Bc_A2Bik9Fz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(1 point) Report the accuracy on both training and test set."
      ],
      "metadata": {
        "id": "pEVCJNDHQRyG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline.score(X_test, y_test)"
      ],
      "metadata": {
        "id": "t5LkgxUIQW7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(1 point) Why is accuracy a sufficient measure of evaluation here?\n",
        "\n",
        "Accuracy is sufficient in our situation since we only have two classes."
      ],
      "metadata": {
        "id": "2FmmYjxqQdOV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Bonus] What are the top 10 most important words (features) for each class? (bonus points"
      ],
      "metadata": {
        "id": "nveDyY4wRZ9G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ranks = []\n",
        "for prob in pipeline[1].feature_log_prob_:\n",
        "  ranks.append(prob.argsort()[-10:])\n",
        "ranks"
      ],
      "metadata": {
        "id": "E4mW3focrA8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove stopwords (see NLTK stopwords corpus) and check "
      ],
      "metadata": {
        "id": "X8KOORiYRkn4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize as word_tokenize\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "stops = set(stopwords.words('english'))\n",
        "def remove_stop_words(corpus):\n",
        "  no_stop_reviews = []\n",
        "  for review in corpus:\n",
        "    tokenized = word_tokenize(review)\n",
        "    fix = []\n",
        "    for word in tokenized:\n",
        "      if word not in stops:\n",
        "        fix.append(word)\n",
        "    no_stop_reviews.append(' '.join(fix))\n",
        "  return no_stop_reviews\n",
        "\n",
        "X_train_no_stop = remove_stop_words(X_train)"
      ],
      "metadata": {
        "id": "hRBaGJvEwecq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(2 points) Add stemming or lemmatization to your pretreatment."
      ],
      "metadata": {
        "id": "MS5A1P3GRQlA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "no_stop_reviews = []\n",
        "for review in X_train:\n",
        "  tokenized = word_tokenize(review)\n",
        "  fix = []\n",
        "  for word in tokenized:\n",
        "    if word not in stops:\n",
        "      fix.append(word)\n",
        "  no_stop_reviews.append(' '.join(fix))\n",
        "no_stop_reviews[0]"
      ],
      "metadata": {
        "id": "5hbQGCuZshGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(1 point) Train and evaluate your model again with these pretreatment."
      ],
      "metadata": {
        "id": "eELfuC3RRT9l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline.fit(X_train_no_stop, y_train)\n",
        "pipeline.score(X_train_no_stop, y_train)"
      ],
      "metadata": {
        "id": "8h2KRCr4wwiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_no_stop = remove_stop_words(X_test)\n",
        "pipeline.score(X_test, y_test)"
      ],
      "metadata": {
        "id": "Q2-HDIPWw98O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we have a strange behavior where the presence of stopwords in our testing data causes to lose a large amount of accuracy"
      ],
      "metadata": {
        "id": "rPpjYe1rWZj1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "stemmer = PorterStemmer()"
      ],
      "metadata": {
        "id": "NjCNYZtL_2Lc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stem_reviews(reviews):\n",
        "  stemmed_l = []\n",
        "  for review in reviews:\n",
        "    stemmed = [stemmer.stem(elt) for elt in review.split()]\n",
        "    stemmed = ' '.join(stemmed)\n",
        "    stemmed_l.append(stemmed)\n",
        "  return stemmed_l\n",
        "\n",
        "X_train_stem = stem_reviews(X_train)"
      ],
      "metadata": {
        "id": "oQcB6aD7ANdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_stem[0]"
      ],
      "metadata": {
        "id": "7iszOp-EmDRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_stem = stem_reviews(X_test)\n",
        "pipeline.fit(X_train_stem, y_train)\n",
        "pipeline.score(X_train_stem, y_train)\n",
        "pipeline.score(X_test_stem, y_test)"
      ],
      "metadata": {
        "id": "23L1CnGImsAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will now try to apply similar methods but with lemming and compare results."
      ],
      "metadata": {
        "id": "Go2kuJiRXPEA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "Ub4aMjpvlTqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lemma_reviews(reviews):\n",
        "  lemm_l = []\n",
        "  for review in reviews:\n",
        "    lem = [lemmatizer.lemmatize(elt) for elt in review.split()]\n",
        "    lem = ' '.join(lem)\n",
        "    lemm_l.append(lem)\n",
        "  return lemm_l"
      ],
      "metadata": {
        "id": "0eY4ThNbmSOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_lem = lemma_reviews(X_train)\n",
        "X_test_lem = lemma_reviews(X_test)\n",
        "pipeline.fit(X_train_lem, y_train)\n",
        "pipeline.score(X_train_lem, y_train)\n",
        "pipeline.score(X_test_lem, y_test)"
      ],
      "metadata": {
        "id": "1gq3D0SxmnMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(1 point) Are the results better or worse? Try explaining why the accuracy changed."
      ],
      "metadata": {
        "id": "q_ggVw6oR7qd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In our situation it seems the accuracy barely changed. The main advantage of the lemma and stemming techniques is to reduce the volume of our vocabulary. If the corpora was overly large, we may have a situation where lemming/stemming could have brought a gain in accuracy. However in our situation the fact words are inflected adds better context and therefore aids the model in its precision."
      ],
      "metadata": {
        "id": "RoED-SbgWvcW"
      }
    }
  ]
}