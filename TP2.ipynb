{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DzGZTNFpYu8i",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "!pip install fastText\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7ltOVkkSJg9"
      },
      "source": [
        "(2 points) Turn the dataset into a dataset compatible with Fastext (see the Tips on using FastText section a bit lower).\n",
        "\n",
        "    For pretreatment, only apply lower casing and punctuation removal.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZCnT59IYYcrq",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import fasttext\n",
        "from datasets import load_dataset\n",
        "\n",
        "dataset_train = load_dataset('imdb', split='train')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Wt2mp3BuSJhC"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cViOv7nrcRyZ"
      },
      "outputs": [],
      "source": [
        "from string import punctuation\n",
        "\n",
        "\n",
        "def to_lower(review: str):\n",
        "\treturn str.lower(review)\n",
        "\n",
        "\n",
        "def no_punct(review: str):\n",
        "\treturn review.translate(str.maketrans('', '', punctuation))\n",
        "\n",
        "\n",
        "def to_fasttext(review: str, label: int):\n",
        "\n",
        "\tlabel_str = 'positive'\n",
        "\tif label == 0:\n",
        "\t\tlabel_str = 'negative'\n",
        "\treturn '__label__' + label_str + \" \" + review\n",
        "\n",
        "\n",
        "def pretreatment(dataset: dict):\n",
        "\tlabels = dataset['label']\n",
        "\treviews = dataset['text']\n",
        "\tcorrected_review_list = []\n",
        "\tfor i in range(len(reviews)):\n",
        "\t\tlower = to_lower(reviews[i])\n",
        "\t\tno_punc = no_punct(lower)\n",
        "\t\tcorrected_review = to_fasttext(no_punc, labels[i])\n",
        "\t\tcorrected_review_list.append(corrected_review)\n",
        "\treturn corrected_review_list\n",
        "\n",
        "def write_into_file(file_path: str, data: list):\n",
        "\twith open(file_path, mode=\"w\") as file:\n",
        "\t\tfile.write(\"\\n\".join(data))\n",
        "\n",
        "\n",
        "\n",
        "X_train_treated = pretreatment(dataset_train)\n",
        "random.shuffle(X_train_treated)\n",
        "write_into_file(\"X_train.txt\", X_train_treated)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWch6APtSJhE"
      },
      "source": [
        "(2 points) Train a FastText classifier with default parameters on the training data, and evaluate it on the test data using accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "RrcN56qASJhF"
      },
      "outputs": [],
      "source": [
        "model = fasttext.train_supervised(input=\"X_train.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "GVB5y_hrSJhF"
      },
      "outputs": [],
      "source": [
        "dataset_test = load_dataset(\"imdb\", split=\"test\")\n",
        "X_test_treated = pretreatment(dataset_test)\n",
        "random.shuffle(X_test_treated)\n",
        "X_test_treated[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "9e1__yVXSJhH"
      },
      "outputs": [],
      "source": [
        "write_into_file(\"X_test.txt\",X_test_treated)\n",
        "model.test(\"X_test.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "iqz_rBS9SJhI"
      },
      "outputs": [],
      "source": [
        "model.test(\"X_train.txt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gUSpEapSJhJ"
      },
      "source": [
        "(3 points) Use the hyperparameters search functionality of FastText and repeat step 2.\n",
        "\n",
        "    To do so, you'll need to split your training set into a training and a validation set (don't forget to shuffle your dataset).\n",
        "    Let the model search for 5 minutes (it's the default search time).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "b7LaKko-SJhK"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_vallidation = train_test_split(X_train_treated, shuffle=True)\n",
        "write_into_file(\"X_train.txt\",X_train)\n",
        "write_into_file(\"X_val.txt\", X_vallidation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "4WfayQIUSJhL"
      },
      "outputs": [],
      "source": [
        "model2 = fasttext.train_supervised(input=\"X_train.txt\",autotuneValidationFile=\"X_val.txt\")\n",
        "model2.test(\"X_test.txt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GdMpM14SJhL"
      },
      "source": [
        " (1 points) Look at the differences between the default model and the attributes found with hyperparameters search. How do the two models differ?\n",
        "\n",
        "    Check the Tips on using FastText section for a bit of help).\n",
        "    Only refer to the attributes you think are interesting.\n",
        "    See the Tips on using FastText (just below) for help.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "xXjl-r_rSJhM"
      },
      "outputs": [],
      "source": [
        "print(\"\t   Model1 |  Model2 \")\n",
        "def my_print(name: str, val1: str, val2 :str):\n",
        "\tprint(f\"{name}:  {val1}    | {val2}\")\n",
        "my_print(\"Epoch\",model.epoch,model2.epoch)\n",
        "my_print(\"Dim\",model.dim,model2.dim) #Pas sur que ce soit intérréssant\n",
        "my_print(\"Bucket\",model.bucket,model2.bucket)\n",
        "my_print(\"Loss function\", model.loss,model2.loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGKs0wDQSJhN"
      },
      "source": [
        "(1 point) Using the tuned model, take at least 2 wrongly classified examples from the test set, and try explaining why the model failed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "uWMrVmjDSJhN"
      },
      "outputs": [],
      "source": [
        "Y_test = model2.predict(X_test_treated)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "lLE-Mto7SJhN"
      },
      "outputs": [],
      "source": [
        "for i,j in enumerate(X_test_treated):\n",
        "\tprint(i,j[9:16])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "44DyeHQLSJhO"
      },
      "outputs": [],
      "source": [
        "print(X_test_treated[11],Y_test[0][11])\n",
        "print(X_test_treated[15],Y_test[0][15])\n",
        "print(X_test_treated[38],Y_test[0][38])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "bppZRhgeSJhO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}